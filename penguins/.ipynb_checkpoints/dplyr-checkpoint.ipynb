{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction: why dplyr?\n",
    "\n",
    "There are a _lot_ of amazing packages in the [Tidyverse](https://www.tidyverse.org/packages/), but `dplyr` is hands-down my absolute favorite package. I use `dplyr` when I'm cleaning and exploring my dataset, and what I particularly love is that after I get a good handle on my dataset with `dplyr`, I can feed the various manipulations I've creating into the `ggplot2` package for visualization.  \n",
    "\n",
    "This tutorial is for anyone interested in learning the basics of the `dplyr` package. We'll be focusing on data exploration and manipulation, building off of the examples in the `dplyr` package documentation using the [Palmer Penguins](https://www.kaggle.com/parulpandey/palmer-archipelago-antarctica-penguin-data) dataset.   \n",
    "\n",
    "**By the end of this notebook, you'll be able to:**  \n",
    "* Demonstrate what each of the main five `dplyr` functions does\n",
    "* Use the pipe operator `%>%` to chain together multiple `dplyr` functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My analytical workflow\n",
    "\n",
    "We won't be covering _all_ of the steps in my workflow in this tutorial, but in general I follow these steps: \n",
    "\n",
    "1. Set up the programming environment by loading packages  \n",
    "2. Import my data  \n",
    "3. Check out my data \n",
    "4. Explore my data \n",
    "5. Model my data\n",
    "6. Communicate what I've learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up our environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "051d70d956493feee0c6d64651c6a088724dca2a",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# we have a couple of options here - we can load the entire tidyverse or we can just load the\n",
    "# tidyverse packages that we're interested in using. I'm going to load the tidyverse, but alternatively you\n",
    "# could run the following instead:\n",
    "\n",
    "# library(readr)\n",
    "# library(dplyr)\n",
    "\n",
    "# load the tidyverse\n",
    "library(tidyverse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A quick note on Conflicts\n",
    "\n",
    "After running `library(tidyverse)` you might have noticed that the print out told us which packages were attached successfully (all of them, as evidenced by the green check marks), and where we have conflicts (the red x's).  \n",
    "\n",
    "Conflicts aren't necessarily a bad thing! Because R is an open source language and anyone can create a package, it's common for different packages to use the same name for similar functions. In our conflicts we see that the `filter()` function from the `dplyr` package masks the `filter()` function from the `stats` package. We know this because the package name comes before the double colon and the function name comes after, like this:  \n",
    "\n",
    "> `package::function()`\n",
    "\n",
    "What if we want to use the `filter()` function from the stats package? All is not lost! What we can do in our code is use the full `package::function()` syntax and R will know to use the `filter()` function from the `stats` package instead of the `dplyr` package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "penguins <- read_csv(\"./penguins_size.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the parsing statement\n",
    "\n",
    "One thing that took me awhile to get used to was that just because the text is in BRIGHT RED doesn't mean that something bad has happened, or that I've made a mistake. And that's the same as what we're seeing here!    \n",
    "\n",
    "What the parsing statement does is tell us how R formatted each of the columns in our dataframe. The `read_csv()` function looks at the first thousand rows of a dataset and makes an educated guess as to what the remaining rows are. We can override this if we need to, either by telling R to use more rows to guess using the `guess_max` argument, or by explicitly telling R what type of data is in each column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check out our data\n",
    "\n",
    "Here's where I like to get a handle on what I'm working with. I'll use various functions to make sure my data imported correctly, and start to get an understanding of the data structure and data types. The functions I commonly use to accomplish this are:  \n",
    "\n",
    "* `glimpse()`\n",
    "* `head()` and `tail()`\n",
    "* `summary()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### glimpse() is grrrreat!\n",
    "\n",
    "`glimpse()` gives you just about everything you could want, all wrapped up in a single function. We get our dataframe structure with the printout to rows and columns, telling us that in our `penguins` dataset we have 344 rows (or observations) and 7 columns (or variables).  \n",
    "\n",
    "![](http://)We also see each of the variables listed out by name, followed by the data type `<datatype>`, and then a look at the first few rows of each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "glimpse(penguins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The heck is a culmen?\n",
    "\n",
    "> I didn't know either, but [Allison Horst](https://twitter.com/allison_horst) has an amazing illustration explaining it!\n",
    "\n",
    "![](https://pbs.twimg.com/media/EaAXQn8U4AAoKUj.jpg:small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### head()\n",
    "\n",
    "Before reading further (or running the code) take a second to think about what the `head()` function might return.  \n",
    "\n",
    "If you guessed the \"head\" of the dataframe, or the first few rows, you'd be correct! I use `head()` to check a couple of things. First, I want to see if my data imported correctly. It's not uncommon to have the first few rows of a `.csv` file be blank, or contain information that I don't want in my final dataset. Second, `head()` prints out a nicely-formatted table that lets me take a quick look and see if the data is formatted consistently.  \n",
    "\n",
    "Using `head()` and seeing that your data is formatted consistently isn't a guarantee that you won't run into problems later, but it's a great first check.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "head(penguins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### summary()\n",
    "\n",
    "`summary()` might be one of the first functions I remember using and going \"ooooh, this is pretty cool!\" Like with the `head()` function, the name tells you what it does - any data that we pass to `summary()` will return a set of summary statistics appropriate for that datatype.  \n",
    "\n",
    "We can send individual variables to `summary()`, or an entire dataframe, and get a quick idea of our data types, the spread of our data, and an idea of how much missing missing data we'll be dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "summary(penguins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a note on names()\n",
    "\n",
    "I have a really hard time remembering what the names of my variables are, and because R is case-sensitive, how the names are formatted. We could fix this by converting all of our variable names to the same case, but for now just know that if you ever need a refresher on the names of the variables in your dataset (and how they're formatted!) you can run `names()`, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "names(penguins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring our data with dplyr\n",
    "\n",
    "**Main functions we'll use**\n",
    "* `arrange()`\n",
    "* `filter()`\n",
    "* `select()`\n",
    "* `mutate()`\n",
    "* `summarise()` (you can also use `summarize()`)\n",
    "\n",
    "**Reading and writing R code**  \n",
    "One thing that I really enjoy about working in R is that I can write out what I want to do in a sentence, and then translate that into code. For example, if I say:\n",
    "\n",
    "> Take the penguins dataset and then filter for all penguins that live on Torgersen island\n",
    "\n",
    "* _Take the penguins dataset_ **translates to** `penguins`\n",
    "* _and then_ **translates to** `%>%`\n",
    "* _filter for all penguins that live on Torgersen island_ **translates to** `filter(island == \"Torgersen\")`\n",
    "\n",
    "We can then take these three lines and put them together to get the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "penguins %>%\n",
    "  filter(island == \"Torgersen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait what the heck is %>%?\n",
    "\n",
    "`%>%` is the pipe operator, and it allows us to push our data through sequential functions in R. Much like we use the words \"and then\" to describe instructions or steps on how to do something, `%>%` acts like an \"and then\" statement between functions.  \n",
    "\n",
    "We can take the code we wrote above _and then_ add a function we've already used, `head()` to print out a much shorter table, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "penguins %>%\n",
    "  filter(island == \"Torgersen\") %>%\n",
    "  head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's get to it! In this section we'll go through a couple of examples with each of the individual `dplyr` functions, and then start combining them to do some powerful data manipulations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying arrange()\n",
    "\n",
    "`arrange()` \"arranges,\" or organizes, our data in _ascending_ order, starting from the lowest value and running to the highest (or in the case of character data, in alphabetical order).  \n",
    "\n",
    "We can provide a single argument to the `arrange()` function, such as `culmen_length_mm` (double) or `species` (character)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# numeric data\n",
    "# I've added the head() function to the end of the function chain to reduce the length of the table that's printed out\n",
    "# you can remove it in your version!\n",
    "\n",
    "penguins %>%\n",
    "  arrange(culmen_length_mm) %>%\n",
    "  head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# character data\n",
    "\n",
    "penguins %>%\n",
    "  arrange(species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a subset\n",
    "\n",
    "It's a little hard to see what's going on in the above table, so I'm going to create a smaller subset of the `penguins` dataset so that we can see what's going on a bit more clearly. You can run the code on the subset of the data, or replace `penguins_subset` with `penguins` to see what happens on the full dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# creating a random subset of the penguins dataset\n",
    "set.seed(406)\n",
    "\n",
    "penguins_subset <- penguins %>%\n",
    "  sample_n(12)  # another dplyr function!\n",
    "\n",
    "penguins_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# let's re-run the arrange() function on character data in the penguins_subset data\n",
    "\n",
    "penguins_subset %>%\n",
    "  arrange(species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nesting desc() inside arrange()\n",
    "\n",
    "What if we don't want our data in ascending order? Then we can nest the `desc()` function, which stands for _descending_, within the `arrange()` function. This will then order our numeric data from highest to lowest, and our character data in reverse alphabetical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# numeric data arranged in descending order\n",
    "\n",
    "penguins_subset %>%\n",
    "  arrange(desc(culmen_length_mm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# character data arranged in descending - reverse alphabetical - order\n",
    "\n",
    "penguins_subset %>%\n",
    "  arrange(desc(species))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fun with filter()\n",
    "\n",
    "`filter()` is probably one of my most used functions, because it allows me to look at subsets quickly and easily. What's nice about `filter()` is its flexibility - we can use it on a single condition or multiple conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# filter with a single numeric condition\n",
    "\n",
    "penguins_subset %>%\n",
    "  filter(culmen_depth_mm > 16.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# filter with a single character condition\n",
    "\n",
    "penguins_subset %>%\n",
    "  filter(island == \"Dream\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# filter with a single numeric condition between two values\n",
    "\n",
    "penguins_subset %>%\n",
    "  filter(between(culmen_depth_mm, 16.2, 18.1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting with select()\n",
    "\n",
    "`select()` allows us to pick which columns (variables) we want to look at, and we can use it to pull a subset of variables, or even rearrange the order of our variables within a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# selecting species, flipper_length_mm, and sex columns\n",
    "\n",
    "penguins_subset %>%\n",
    "  select(species, flipper_length_mm, sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# selecting all character data\n",
    "\n",
    "penguins_subset %>%\n",
    "  select(where(is.character))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# selecting all numeric data\n",
    "\n",
    "penguins_subset %>%\n",
    "  select(where(is.numeric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# selecting all character data by using \"where not numeric\" data\n",
    "\n",
    "penguins_subset %>%\n",
    "  select(!where(is.numeric))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Math with mutate()\n",
    "\n",
    "What's not to love about a function that let's us create new columns (variables)?! For these examples we'll work strictly with `mutate()`, but when you work on extending this notebook, try using `group_by()` and _then_ `mutate()`! (We'll talk about `group_by()` in the next section.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# converting grams to pounds\n",
    "# notice how the order of our columns stays the same, and the new column, body_weight_pounds, gets placed at the\n",
    "# far right of the dataframe. what function could we use to change this order?\n",
    "\n",
    "penguins_subset %>%\n",
    "  mutate(body_weight_pounds = body_mass_g / 453.59237)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# OK I wanted to show you how to combine select and mutate\n",
    "# what do you think the everything() function might do? confirm your guess by looking at the documentation (linked at\n",
    "# the end of the notebook).\n",
    "\n",
    "penguins_subset %>%\n",
    "  mutate(body_weight_pounds = body_mass_g / 453.59237) %>%\n",
    "  select(species, body_mass_g, body_weight_pounds, everything())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summaries with summarise(), with help from group_by()\n",
    "\n",
    "You can use either `summarise()` or `summarize()` to get a summary, or overview, of your data. What's more, once we introduce `group_by()` you can get summary data for _subsets_ of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# summarising the average body mass of penguins, in grams\n",
    "\n",
    "penguins_subset %>%\n",
    "  summarise(avg_body_mass = mean(body_mass_g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# since we're now summarising our data we can go ahead and use the full dataframe,\n",
    "# since the printout will be reasonably-sized\n",
    "\n",
    "penguins %>%\n",
    "  summarise(avg_body_mass = mean(body_mass_g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The NAs!\n",
    "\n",
    "If we don't handle our `NA` values we're going to be in for a bad time. There are multiple ways of dealing with `NA` values in R - for now we're going to use `na.rm = TRUE`, but you could use `filter()` from the `dplyr` package or `drop_na()` from the `tidyr` package as well!  \n",
    "\n",
    "`na.rm` is like asking the question, \"Should we remove `NA`s from our code?\" where `na` stands for `NA` values, and `rm` stands for remove. So when we set `na.rm = TRUE` we're saying \"Yes, please remove `NA` values from my calculations.\" Likewise if we use `na.rm = FALSE` we're telling R that we want to include `NA` values in our calculations.  \n",
    "\n",
    "And if you're not sure, `NA` stands for \"Not Available,\" meaning data that is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# summarising body mass on the entire penguins dataset while removing NA values from the calculation\n",
    "\n",
    "penguins %>%\n",
    "  summarise(avg_body_mass = mean(body_mass_g, na.rm = TRUE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# now let's use the grouping function, group_by(), to look at the average body mass of penguins, in grams,\n",
    "# by species\n",
    "\n",
    "penguins %>%\n",
    "  group_by(species) %>%\n",
    "  summarise(avg_species_body_mass = mean(body_mass_g, na.rm = TRUE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# now let's calculate the average body mass by species AND island\n",
    "\n",
    "penguins %>%\n",
    "  group_by(species, island) %>%\n",
    "  summarise(avg_species_body_mass = mean(body_mass_g, na.rm = TRUE))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where to next?\n",
    "\n",
    "What we've done here only scratches the surface of what you can accomplish with `dplyr`. `dplyr` is a powerful package in its own right, but even more so once you dive into column-wise operations, like `across()`, as well as combine it with other packages in the Tidyverse, such as `purrr` and `ggplot2`.  \n",
    "\n",
    "What I recommend is making a copy of this notebook and running the cells to ensure you understand what's happening with each function, and then build out additional chains of `dplyr` functions to see what you can discover and learn! Play around and don't worry about making mistakes - it's all part of learning!   \n",
    "\n",
    "These are some helpful resources to get you started:  \n",
    "\n",
    "* [`dplyr` documentation - so many functions!](https://dplyr.tidyverse.org/reference/index.html)\n",
    "* [R for Data Science text](https://r4ds.had.co.nz/transform.html)\n",
    "* [STAT545](https://stat545.com/)\n",
    "* [More on column-wise operations](https://dplyr.tidyverse.org/articles/colwise.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
